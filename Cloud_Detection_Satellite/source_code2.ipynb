{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshgupta1998/Image_Processing/blob/master/Cloud_Detection_Satellite/source_code2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1nBNcC_agkM",
        "colab_type": "text"
      },
      "source": [
        "#Understanding Clouds from Satellite Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpc_e0lhaCJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cloud_Detection_Satellite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKfZeg1VaCMA",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "061d8d9f-8b04-4444-de1c-0798a7ae75f0"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8312188-b6b0-4c73-9553-a30fe2dedeaf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c8312188-b6b0-4c73-9553-a30fe2dedeaf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu-JzepDaCN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f33b91eb-eb5e-4b1d-9209-22adeee6a7c2"
      },
      "source": [
        "!kaggle competitions download -c understanding_cloud_organization"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train_images.zip to /content\n",
            "100% 3.44G/3.44G [00:45<00:00, 59.2MB/s]\n",
            "100% 3.44G/3.44G [00:45<00:00, 81.6MB/s]\n",
            "Downloading test_images.zip to /content\n",
            "100% 2.29G/2.30G [00:39<00:00, 70.3MB/s]\n",
            "100% 2.30G/2.30G [00:39<00:00, 62.0MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 96% 52.0M/54.2M [00:00<00:00, 44.8MB/s]\n",
            "100% 54.2M/54.2M [00:01<00:00, 55.9MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/321k [00:00<?, ?B/s]\n",
            "100% 321k/321k [00:00<00:00, 103MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6_d4UxhjmBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils import Sequence\n",
        "from albumentations import Compose, VerticalFlip, HorizontalFlip, Rotate, GridDistortion\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from numpy.random import seed\n",
        "seed(10)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(10)\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmKjDVNVjmOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras-rectified-adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNfDCaXRjmTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_imgs_folder = '../input/understanding_cloud_organization/test_images/'\n",
        "train_imgs_folder = '../input/understanding_cloud_organization/train_images/'\n",
        "num_cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X4jpnB9kQ_l",
        "colab_type": "text"
      },
      "source": [
        "#Data Generators\n",
        "One-hot encoding classes¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfYuX4rVjmXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('../input/understanding_cloud_organization/train.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o7FxOTYjmkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df[~train_df['EncodedPixels'].isnull()]\n",
        "train_df['Image'] = train_df['Image_Label'].map(lambda x: x.split('_')[0])\n",
        "train_df['Class'] = train_df['Image_Label'].map(lambda x: x.split('_')[1])\n",
        "classes = train_df['Class'].unique()\n",
        "train_df = train_df.groupby('Image')['Class'].agg(set).reset_index()\n",
        "for class_name in classes:\n",
        "    train_df[class_name] = train_df['Class'].map(lambda x: 1 if class_name in x else 0)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fqfA0ZrjmjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dictionary for fast access to ohe vectors\n",
        "img_2_ohe_vector = {img:vec for img, vec in zip(train_df['Image'], train_df.iloc[:, 2:].values)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAUJFQODkiqP",
        "colab_type": "text"
      },
      "source": [
        "#Stratified split into train/val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgoPig8mn79n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs, val_imgs = train_test_split(train_df['Image'].values, \n",
        "                                        test_size=0.2, \n",
        "                                        stratify=train_df['Class'].map(lambda x: str(sorted(list(x)))), # sorting present classes in lexicographical order, just to be sure\n",
        "                                        random_state=2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHzYNA57n78G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T53Y2SuVn720",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaM6YcSxoFD1",
        "colab_type": "text"
      },
      "source": [
        "#Generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuT3tb5Nn7zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class DataGenenerator(Sequence):\n",
        "    def __init__(self, images_list=None, folder_imgs=train_imgs_folder, \n",
        "                 batch_size=32, shuffle=True, augmentation=None,\n",
        "                 resized_height=260, resized_width=260, num_channels=3):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augmentation = augmentation\n",
        "        if images_list is None:\n",
        "            self.images_list = os.listdir(folder_imgs)\n",
        "        else:\n",
        "            self.images_list = deepcopy(images_list)\n",
        "        self.folder_imgs = folder_imgs\n",
        "        self.len = len(self.images_list) // self.batch_size\n",
        "        self.resized_height = resized_height\n",
        "        self.resized_width = resized_width\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = 4\n",
        "        self.is_test = not 'train' in folder_imgs\n",
        "        if not shuffle and not self.is_test:\n",
        "            self.labels = [img_2_ohe_vector[img] for img in self.images_list[:self.len*self.batch_size]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def on_epoch_start(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.images_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        current_batch = self.images_list[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "        X = np.empty((self.batch_size, self.resized_height, self.resized_width, self.num_channels))\n",
        "        y = np.empty((self.batch_size, self.num_classes))\n",
        "\n",
        "        for i, image_name in enumerate(current_batch):\n",
        "            path = os.path.join(self.folder_imgs, image_name)\n",
        "            img = cv2.resize(cv2.imread(path), (self.resized_height, self.resized_width)).astype(np.float32)\n",
        "            if not self.augmentation is None:\n",
        "                augmented = self.augmentation(image=img)\n",
        "                img = augmented['image']\n",
        "            X[i, :, :, :] = img/255.0\n",
        "            if not self.is_test:\n",
        "                y[i, :] = img_2_ohe_vector[image_name]\n",
        "        return X, y\n",
        "\n",
        "    def get_labels(self):\n",
        "        if self.shuffle:\n",
        "            images_current = self.images_list[:self.len*self.batch_size]\n",
        "            labels = [img_2_ohe_vector[img] for img in images_current]\n",
        "        else:\n",
        "            labels = self.labels\n",
        "        return np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "micEbt_BjmhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "albumentations_train = Compose([\n",
        "    VerticalFlip(), HorizontalFlip(), Rotate(limit=20), GridDistortion()\n",
        "], p=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9bDVpI_n5QX",
        "colab_type": "text"
      },
      "source": [
        "#Generator instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_G_HDCijmfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_generator_train = DataGenenerator(train_imgs, augmentation=albumentations_train)\n",
        "data_generator_train_eval = DataGenenerator(train_imgs, shuffle=False)\n",
        "data_generator_val = DataGenenerator(val_imgs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPYiSI70nzTy",
        "colab_type": "text"
      },
      "source": [
        "#PR-AUC-based Callback\n",
        "The callback would be used:\n",
        "\n",
        "to estimate AUC under precision recall curve for each class,\n",
        "to early stop after 5 epochs of no improvement in mean PR AUC,\n",
        "save a model with the best PR AUC in validation,\n",
        "to reduce learning rate on PR AUC plateau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwUdvJiMjmeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrAucCallback(Callback):\n",
        "    def __init__(self, data_generator, num_workers=num_cores, \n",
        "                 early_stopping_patience=5, \n",
        "                 plateau_patience=3, reduction_rate=0.5,\n",
        "                 stage='train', checkpoints_path='checkpoints/'):\n",
        "        super(Callback, self).__init__()\n",
        "        self.data_generator = data_generator\n",
        "        self.num_workers = num_workers\n",
        "        self.class_names = ['Fish', 'Flower', 'Sugar', 'Gravel']\n",
        "        self.history = [[] for _ in range(len(self.class_names) + 1)] # to store per each class and also mean PR AUC\n",
        "        self.early_stopping_patience = early_stopping_patience\n",
        "        self.plateau_patience = plateau_patience\n",
        "        self.reduction_rate = reduction_rate\n",
        "        self.stage = stage\n",
        "        self.best_pr_auc = -float('inf')\n",
        "        if not os.path.exists(checkpoints_path):\n",
        "            os.makedirs(checkpoints_path)\n",
        "        self.checkpoints_path = checkpoints_path\n",
        "        \n",
        "    def compute_pr_auc(self, y_true, y_pred):\n",
        "        pr_auc_mean = 0\n",
        "        print(f\"\\n{'#'*30}\\n\")\n",
        "        for class_i in range(len(self.class_names)):\n",
        "            precision, recall, _ = precision_recall_curve(y_true[:, class_i], y_pred[:, class_i])\n",
        "            pr_auc = auc(recall, precision)\n",
        "            pr_auc_mean += pr_auc/len(self.class_names)\n",
        "            print(f\"PR AUC {self.class_names[class_i]}, {self.stage}: {pr_auc:.3f}\\n\")\n",
        "            self.history[class_i].append(pr_auc)        \n",
        "        print(f\"\\n{'#'*20}\\n PR AUC mean, {self.stage}: {pr_auc_mean:.3f}\\n{'#'*20}\\n\")\n",
        "        self.history[-1].append(pr_auc_mean)\n",
        "        return pr_auc_mean\n",
        "              \n",
        "    def is_patience_lost(self, patience):\n",
        "        if len(self.history[-1]) > patience:\n",
        "            best_performance = max(self.history[-1][-(patience + 1):-1])\n",
        "            return best_performance == self.history[-1][-(patience + 1)] and best_performance >= self.history[-1][-1]    \n",
        "    def early_stopping_check(self, pr_auc_mean):\n",
        "        if self.is_patience_lost(self.early_stopping_patience):\n",
        "            self.model.stop_training = True    \n",
        "              \n",
        "    def model_checkpoint(self, pr_auc_mean, epoch):\n",
        "        if pr_auc_mean > self.best_pr_auc:\n",
        "            # remove previous checkpoints to save space\n",
        "            for checkpoint in glob.glob(os.path.join(self.checkpoints_path, 'classifier_densenet169_epoch_*')):\n",
        "                os.remove(checkpoint)\n",
        "            self.best_pr_auc = pr_auc_mean\n",
        "            self.model.save(os.path.join(self.checkpoints_path, f'classifier_densenet169_epoch_{epoch}_val_pr_auc_{pr_auc_mean}.h5'))              \n",
        "            print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n",
        "              \n",
        "    def reduce_lr_on_plateau(self):\n",
        "        if self.is_patience_lost(self.plateau_patience):\n",
        "            new_lr = float(keras.backend.get_value(self.model.optimizer.lr)) * self.reduction_rate\n",
        "            keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "            print(f\"\\n{'#'*20}\\nReduced learning rate to {new_lr}.\\n{'#'*20}\\n\")\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        y_pred = self.model.predict_generator(self.data_generator, workers=self.num_workers)\n",
        "        y_true = self.data_generator.get_labels()\n",
        "        # estimate AUC under precision recall curve for each class\n",
        "        pr_auc_mean = self.compute_pr_auc(y_true, y_pred)\n",
        "              \n",
        "        if self.stage == 'val':\n",
        "            # early stop after early_stopping_patience=4 epochs of no improvement in mean PR AUC\n",
        "            self.early_stopping_check(pr_auc_mean)\n",
        "\n",
        "            # save a model with the best PR AUC in validation\n",
        "            self.model_checkpoint(pr_auc_mean, epoch)\n",
        "\n",
        "            # reduce learning rate on PR AUC plateau\n",
        "            self.reduce_lr_on_plateau()            \n",
        "        \n",
        "    def get_pr_auc_history(self):\n",
        "        return self.history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDz_bZtenizx",
        "colab_type": "text"
      },
      "source": [
        "#Callback instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LDN_b2wnGvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_metric_callback = PrAucCallback(data_generator_train_eval)\n",
        "val_callback = PrAucCallback(data_generator_val, stage='val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4IBJv3Qnea-",
        "colab_type": "text"
      },
      "source": [
        "#Classifier¶\n",
        "Defining a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kayij7NWnGuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUVGW2BdnGpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U git+https://github.com/qubvel/efficientnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8NBfAoNnGmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import efficientnet.keras as efn \n",
        "def get_model():\n",
        "    K.clear_session()\n",
        "    base_model =  efn.EfficientNetB2(weights='imagenet', include_top=False, pooling='avg', input_shape=(260, 260, 3))\n",
        "    x = base_model.output\n",
        "    y_pred = Dense(4, activation='sigmoid')(x)\n",
        "    return Model(inputs=base_model.input, outputs=y_pred)\n",
        "\n",
        "model = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgtCbbUFnGkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_radam import RAdam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuMfaKKanUJU",
        "colab_type": "text"
      },
      "source": [
        "#Initial tuning of the added fully-connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKl48R-nGii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for base_layer in model.layers[:-3]:\n",
        "    base_layer.trainable = False\n",
        "    \n",
        "model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-5),  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_0 = model.fit_generator(generator=data_generator_train,\n",
        "                              validation_data=data_generator_val,\n",
        "                              epochs=20,\n",
        "                              callbacks=[train_metric_callback, val_callback],\n",
        "                              workers=num_cores,\n",
        "                              verbose=1\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6mCjZiqnJAX",
        "colab_type": "text"
      },
      "source": [
        "#Fine-tuning the whole model\n",
        "After unfreezing all the layers(except last 3) I set a less aggressive initial learning rate and train until early stopping (or 100 epochs max)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqVJf8uenFzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for base_layer in model.layers[:-3]:\n",
        "    base_layer.trainable = True\n",
        "    \n",
        "model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-5),  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_1 = model.fit_generator(generator=data_generator_train,\n",
        "                              validation_data=data_generator_val,\n",
        "                              epochs=20,\n",
        "                              callbacks=[train_metric_callback, val_callback],\n",
        "                              workers=num_cores,\n",
        "                              verbose=1,\n",
        "                              initial_epoch=1\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_wJhl8rm-cG",
        "colab_type": "text"
      },
      "source": [
        "#Visualizing train and val PR AUC\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYVSGOWrnBeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_with_dots(ax, np_array):\n",
        "    ax.scatter(list(range(1, len(np_array) + 1)), np_array, s=50)\n",
        "    ax.plot(list(range(1, len(np_array) + 1)), np_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbaqA2UYmxJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_auc_history_train = train_metric_callback.get_pr_auc_history()\n",
        "pr_auc_history_val = val_callback.get_pr_auc_history()\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plot_with_dots(plt, pr_auc_history_train[-1])\n",
        "plot_with_dots(plt, pr_auc_history_val[-1])\n",
        "\n",
        "plt.xlabel('Epoch', fontsize=15)\n",
        "plt.ylabel('Mean PR AUC', fontsize=15)\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.title('Training and Validation PR AUC', fontsize=20)\n",
        "plt.savefig('pr_auc_hist.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eaa6q2T5mxGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plot_with_dots(plt, history_0.history['loss']+history_1.history['loss'])\n",
        "plot_with_dots(plt, history_0.history['val_loss']+history_1.history['val_loss'])\n",
        "\n",
        "plt.xlabel('Epoch', fontsize=15)\n",
        "plt.ylabel('Binary Crossentropy', fontsize=15)\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.title('Training and Validation Loss', fontsize=20)\n",
        "plt.savefig('loss_hist.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKhv6SJmxCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(\"../input/clouds-classifier-files/loss_hist_densenet169.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KReyUEz3mxAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(\"../input/clouds-classifier-files/pr_auc_hist_densenet169.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN2KpIaTmu27",
        "colab_type": "text"
      },
      "source": [
        "#Selecting postprocessing thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWqt0s7ZjmcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_threshold_for_recall(y_true, y_pred, class_i, recall_threshold=0.94, precision_threshold=0.90, plot=False):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true[:, class_i], y_pred[:, class_i])\n",
        "    i = len(thresholds) - 1\n",
        "    best_recall_threshold = None\n",
        "    while best_recall_threshold is None:\n",
        "        next_threshold = thresholds[i]\n",
        "        next_recall = recall[i]\n",
        "        if next_recall >= recall_threshold:\n",
        "            best_recall_threshold = next_threshold\n",
        "        i -= 1\n",
        "        \n",
        "    # consice, even though unnecessary passing through all the values\n",
        "    best_precision_threshold = [thres for prec, thres in zip(precision, thresholds) if prec >= precision_threshold][0]\n",
        "    if plot:\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.step(recall, precision, color='r', alpha=0.3, where='post')\n",
        "        plt.fill_between(recall, precision, alpha=0.3, color='r')\n",
        "        plt.axhline(y=precision[i + 1])\n",
        "        recall_for_prec_thres = [rec for rec, thres in zip(recall, thresholds) \n",
        "                                 if thres == best_precision_threshold][0]\n",
        "        plt.axvline(x=recall_for_prec_thres, color='g')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.legend(['PR curve', \n",
        "                    f'Precision {precision[i + 1]: .2f} corresponding to selected recall threshold',\n",
        "                    f'Recall {recall_for_prec_thres: .2f} corresponding to selected precision threshold'])\n",
        "        plt.title(f'Precision-Recall curve for Class {class_names[class_i]}')\n",
        "    return best_recall_threshold, best_precision_threshold\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhmGKyV2mrVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_generator(data_generator_val, workers=num_cores)\n",
        "y_true = data_generator_val.get_labels()\n",
        "recall_thresholds = dict()\n",
        "precision_thresholds = dict()\n",
        "for i, class_name in tqdm(enumerate(class_names)):\n",
        "    recall_thresholds[class_name], precision_thresholds[class_name] = get_threshold_for_recall(y_true, y_pred, i, plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BshfMgZ_lWa_",
        "colab_type": "text"
      },
      "source": [
        "#Post-processing segmentation submission\n",
        "Predicting cloud classes for test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTpXfhtQjmNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_generator_test = DataGenenerator(folder_imgs=test_imgs_folder, shuffle=False)\n",
        "y_pred_test = model.predict_generator(data_generator_test, workers=num_cores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWS3Xj-bjmLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_labels_empty = set()\n",
        "for i, (img, predictions) in enumerate(zip(os.listdir(test_imgs_folder), y_pred_test)):\n",
        "    for class_i, class_name in enumerate(class_names):\n",
        "        if predictions[class_i] < recall_thresholds[class_name]:\n",
        "            image_labels_empty.add(f'{img}_{class_name}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr28Wo_ijmKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('../input/densenet201cloudy/densenet201.csv')\n",
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F29hzWF2jmJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_nonempty = set(submission.loc[~submission['EncodedPixels'].isnull(), 'Image_Label'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7L3LxN_jmGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'{len(image_labels_empty.intersection(predictions_nonempty))} masks would be removed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNWAAS38jmE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing masks\n",
        "submission.loc[submission['Image_Label'].isin(image_labels_empty), 'EncodedPixels'] = np.nan\n",
        "submission.to_csv('submission_segmentation_and_classifier.csv', index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}